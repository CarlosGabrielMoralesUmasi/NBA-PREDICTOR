{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas en 'games': ['season_id', 'team_id_home', 'team_abbreviation_home', 'team_name_home', 'game_id', 'game_date', 'matchup_home', 'wl_home', 'min', 'fgm_home', 'fga_home', 'fg_pct_home', 'fg3m_home', 'fg3a_home', 'fg3_pct_home', 'ftm_home', 'fta_home', 'ft_pct_home', 'oreb_home', 'dreb_home', 'reb_home', 'ast_home', 'stl_home', 'blk_home', 'tov_home', 'pf_home', 'pts_home', 'plus_minus_home', 'video_available_home', 'team_id_away', 'team_abbreviation_away', 'team_name_away', 'matchup_away', 'wl_away', 'fgm_away', 'fga_away', 'fg_pct_away', 'fg3m_away', 'fg3a_away', 'fg3_pct_away', 'ftm_away', 'fta_away', 'ft_pct_away', 'oreb_away', 'dreb_away', 'reb_away', 'ast_away', 'stl_away', 'blk_away', 'tov_away', 'pf_away', 'pts_away', 'plus_minus_away', 'video_available_away', 'season_type']\n",
      "Columnas en 'game_info': ['game_id', 'game_date', 'attendance', 'game_time']\n",
      "Columnas en 'games_full' después de la fusión: ['season_id', 'team_id_home', 'team_abbreviation_home', 'team_name_home', 'game_id', 'game_date_x', 'matchup_home', 'wl_home', 'min', 'fgm_home', 'fga_home', 'fg_pct_home', 'fg3m_home', 'fg3a_home', 'fg3_pct_home', 'ftm_home', 'fta_home', 'ft_pct_home', 'oreb_home', 'dreb_home', 'reb_home', 'ast_home', 'stl_home', 'blk_home', 'tov_home', 'pf_home', 'pts_home', 'plus_minus_home', 'video_available_home', 'team_id_away', 'team_abbreviation_away', 'team_name_away', 'matchup_away', 'wl_away', 'fgm_away', 'fga_away', 'fg_pct_away', 'fg3m_away', 'fg3a_away', 'fg3_pct_away', 'ftm_away', 'fta_away', 'ft_pct_away', 'oreb_away', 'dreb_away', 'reb_away', 'ast_away', 'stl_away', 'blk_away', 'tov_away', 'pf_away', 'pts_away', 'plus_minus_away', 'video_available_away', 'season_type', 'game_date_y', 'attendance', 'game_time']\n"
     ]
    }
   ],
   "source": [
    "# Imprimir nombres de columnas en ambos DataFrames para verificar\n",
    "print(\"Columnas en 'games':\", games.columns.tolist())\n",
    "print(\"Columnas en 'game_info':\", game_info.columns.tolist())\n",
    "\n",
    "# También, verifica si la columna 'game_date' existe después de la fusión\n",
    "games_full = games.merge(game_info, on='game_id', how='left')\n",
    "print(\"Columnas en 'games_full' después de la fusión:\", games_full.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   game_date  team_id_home  team_id_away  pts_home  pts_away  target\n",
      "0 1946-11-01    1610610035    1610612752      66.0      68.0       0\n",
      "1 1946-11-02    1610610034    1610610031      56.0      51.0       1\n",
      "2 1946-11-02    1610610032    1610612738      59.0      53.0       1\n",
      "3 1946-11-02    1610610025    1610612752      63.0      47.0       1\n",
      "4 1946-11-02    1610610028    1610610036      33.0      50.0       0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar datos\n",
    "games = pd.read_csv('C:\\\\Users\\\\carlo\\\\Documents\\\\Proyectos\\\\NBA_predict\\\\csv\\\\game.csv')\n",
    "game_info = pd.read_csv('C:\\\\Users\\\\carlo\\\\Documents\\\\Proyectos\\\\NBA_predict\\\\csv\\\\game_info.csv')\n",
    "\n",
    "# Fusionar DataFrames\n",
    "games_full = games.merge(game_info, on='game_id', how='left', suffixes=('_x', '_y'))\n",
    "\n",
    "# Convertir 'game_date_x' o 'game_date_y' a datetime\n",
    "games_full['game_date'] = pd.to_datetime(games_full['game_date_x'])  # Asume que ambas columnas son intercambiables\n",
    "\n",
    "# Ordenar por fecha\n",
    "games_full.sort_values(by='game_date', inplace=True)\n",
    "\n",
    "# Suponer que 'wl_home' indica si el equipo local ganó o perdió\n",
    "games_full['target'] = (games_full['wl_home'] == 'W').astype(int)\n",
    "\n",
    "# Seleccionar columnas relevantes para el modelo\n",
    "model_data = games_full[['game_date', 'team_id_home', 'team_id_away', 'pts_home', 'pts_away', 'target']]\n",
    "\n",
    "# Ejemplo de cómo proceder después\n",
    "print(model_data.head())\n",
    "\n",
    "# Si necesitas más ayuda con el manejo de datos o con el modelo, avísame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carlo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "C:\\Users\\carlo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "C:\\Users\\carlo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\models\\bert\\modeling_bert.py:439: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1] loss: 0.8199509382247925\n",
      "[1, 11] loss: 0.7678422927856445\n",
      "[1, 21] loss: 0.6669143438339233\n",
      "[1, 31] loss: 0.6967447996139526\n",
      "[1, 41] loss: 0.7156301736831665\n",
      "[1, 51] loss: 0.6641519069671631\n",
      "[1, 61] loss: 0.6800936460494995\n",
      "[1, 71] loss: 0.6790087223052979\n",
      "[1, 81] loss: 0.6683835387229919\n",
      "[1, 91] loss: 0.6334377527236938\n",
      "[1, 101] loss: 0.6835892796516418\n",
      "[1, 111] loss: 0.7137469053268433\n",
      "[1, 121] loss: 0.6832860112190247\n",
      "[1, 131] loss: 0.6827179789543152\n",
      "[1, 141] loss: 0.6313008069992065\n",
      "[1, 151] loss: 0.6671985387802124\n",
      "[1, 161] loss: 0.652488648891449\n",
      "[1, 171] loss: 0.6942811012268066\n",
      "[1, 181] loss: 0.6888742446899414\n",
      "[1, 191] loss: 0.7144515514373779\n",
      "[1, 201] loss: 0.6624429225921631\n",
      "[1, 211] loss: 0.6213627457618713\n",
      "[1, 221] loss: 0.6352006793022156\n",
      "[1, 231] loss: 0.6736316084861755\n",
      "[1, 241] loss: 0.6776243448257446\n",
      "[1, 251] loss: 0.6386815309524536\n",
      "[1, 261] loss: 0.6607494354248047\n",
      "[1, 271] loss: 0.6694372296333313\n",
      "[1, 281] loss: 0.668586790561676\n",
      "[1, 291] loss: 0.6309654116630554\n",
      "[1, 301] loss: 0.6333127021789551\n",
      "[1, 311] loss: 0.7054669857025146\n",
      "[1, 321] loss: 0.6689052581787109\n",
      "[1, 331] loss: 0.6708929538726807\n",
      "[1, 341] loss: 0.6595503687858582\n",
      "[1, 351] loss: 0.6348578333854675\n",
      "[1, 361] loss: 0.6690273880958557\n",
      "[1, 371] loss: 0.6710807085037231\n",
      "[1, 381] loss: 0.6309383511543274\n",
      "[1, 391] loss: 0.6883062124252319\n",
      "[1, 401] loss: 0.6732898950576782\n",
      "[1, 411] loss: 0.6921816468238831\n",
      "[1, 421] loss: 0.6611124277114868\n",
      "[1, 431] loss: 0.6455103754997253\n",
      "[1, 441] loss: 0.6380637884140015\n",
      "[1, 451] loss: 0.645002543926239\n",
      "[1, 461] loss: 0.626579225063324\n",
      "[1, 471] loss: 0.6630281805992126\n",
      "[1, 481] loss: 0.6436578631401062\n",
      "[1, 491] loss: 0.675931453704834\n",
      "[1, 501] loss: 0.6837121844291687\n",
      "[1, 511] loss: 0.6497347950935364\n",
      "[1, 521] loss: 0.7187259793281555\n",
      "[1, 531] loss: 0.7023940682411194\n",
      "[1, 541] loss: 0.6164681911468506\n",
      "[1, 551] loss: 0.6209965944290161\n",
      "[1, 561] loss: 0.6572288274765015\n",
      "[1, 571] loss: 0.7611052393913269\n",
      "[1, 581] loss: 0.6842533349990845\n",
      "[1, 591] loss: 0.6672165989875793\n",
      "[1, 601] loss: 0.754732608795166\n",
      "[1, 611] loss: 0.6484954953193665\n",
      "[1, 621] loss: 0.7115731239318848\n",
      "[1, 631] loss: 0.7115910649299622\n",
      "[1, 641] loss: 0.6153888702392578\n",
      "[1, 651] loss: 0.6239728927612305\n",
      "[1, 661] loss: 0.6980847716331482\n",
      "[1, 671] loss: 0.7422574758529663\n",
      "[1, 681] loss: 0.6119192242622375\n",
      "[1, 691] loss: 0.7157008647918701\n",
      "[1, 701] loss: 0.6612470746040344\n",
      "[1, 711] loss: 0.6268274188041687\n",
      "[1, 721] loss: 0.6414392590522766\n",
      "[1, 731] loss: 0.6498215198516846\n",
      "[1, 741] loss: 0.6705893278121948\n",
      "[1, 751] loss: 0.5674858093261719\n",
      "[1, 761] loss: 0.6821656823158264\n",
      "[1, 771] loss: 0.7067526578903198\n",
      "[1, 781] loss: 0.6747341752052307\n",
      "[1, 791] loss: 0.693579375743866\n",
      "[1, 801] loss: 0.7072669267654419\n",
      "[1, 811] loss: 0.7279158234596252\n",
      "[1, 821] loss: 0.6303707957267761\n",
      "[2, 1] loss: 0.6803032159805298\n",
      "[2, 11] loss: 0.627775251865387\n",
      "[2, 21] loss: 0.69100421667099\n",
      "[2, 31] loss: 0.6901729702949524\n",
      "[2, 41] loss: 0.6722478270530701\n",
      "[2, 51] loss: 0.628209114074707\n",
      "[2, 61] loss: 0.7013286352157593\n",
      "[2, 71] loss: 0.7124696969985962\n",
      "[2, 81] loss: 0.6659064888954163\n",
      "[2, 91] loss: 0.6585668921470642\n",
      "[2, 101] loss: 0.6515053510665894\n",
      "[2, 111] loss: 0.6823731064796448\n",
      "[2, 121] loss: 0.673333466053009\n",
      "[2, 131] loss: 0.7095722556114197\n",
      "[2, 141] loss: 0.6804818511009216\n",
      "[2, 151] loss: 0.6430684924125671\n",
      "[2, 161] loss: 0.6475875377655029\n",
      "[2, 171] loss: 0.6141521334648132\n",
      "[2, 181] loss: 0.6877367496490479\n",
      "[2, 191] loss: 0.6601693034172058\n",
      "[2, 201] loss: 0.6647374033927917\n",
      "[2, 211] loss: 0.639178991317749\n",
      "[2, 221] loss: 0.646673321723938\n",
      "[2, 231] loss: 0.663474440574646\n",
      "[2, 241] loss: 0.6956948041915894\n",
      "[2, 251] loss: 0.6990208625793457\n",
      "[2, 261] loss: 0.5949831008911133\n",
      "[2, 271] loss: 0.6174741983413696\n",
      "[2, 281] loss: 0.6543684005737305\n",
      "[2, 291] loss: 0.6342629194259644\n",
      "[2, 301] loss: 0.6572121977806091\n",
      "[2, 311] loss: 0.7030473947525024\n",
      "[2, 321] loss: 0.6772323846817017\n",
      "[2, 331] loss: 0.7025803327560425\n",
      "[2, 341] loss: 0.6603497266769409\n",
      "[2, 351] loss: 0.6519254446029663\n",
      "[2, 361] loss: 0.68929523229599\n",
      "[2, 371] loss: 0.7155358791351318\n",
      "[2, 381] loss: 0.665376603603363\n",
      "[2, 391] loss: 0.640720784664154\n",
      "[2, 401] loss: 0.6759822964668274\n",
      "[2, 411] loss: 0.6230063438415527\n",
      "[2, 421] loss: 0.6928776502609253\n",
      "[2, 431] loss: 0.6226271390914917\n",
      "[2, 441] loss: 0.7058237195014954\n",
      "[2, 451] loss: 0.6758489608764648\n",
      "[2, 461] loss: 0.6581516861915588\n",
      "[2, 471] loss: 0.6922441720962524\n",
      "[2, 481] loss: 0.6653358340263367\n",
      "[2, 491] loss: 0.6998828649520874\n",
      "[2, 501] loss: 0.6366948485374451\n",
      "[2, 511] loss: 0.6934029459953308\n",
      "[2, 521] loss: 0.6809260249137878\n",
      "[2, 531] loss: 0.6757038235664368\n",
      "[2, 541] loss: 0.6611226797103882\n",
      "[2, 551] loss: 0.671434223651886\n",
      "[2, 561] loss: 0.6893651485443115\n",
      "[2, 571] loss: 0.6891763806343079\n",
      "[2, 581] loss: 0.6551395058631897\n",
      "[2, 591] loss: 0.6593418121337891\n",
      "[2, 601] loss: 0.6485228538513184\n",
      "[2, 611] loss: 0.6111299395561218\n",
      "[2, 621] loss: 0.6552276611328125\n",
      "[2, 631] loss: 0.6806420087814331\n",
      "[2, 641] loss: 0.6552259922027588\n",
      "[2, 651] loss: 0.6761581301689148\n",
      "[2, 661] loss: 0.6750919818878174\n",
      "[2, 671] loss: 0.6831044554710388\n",
      "[2, 681] loss: 0.6418341994285583\n",
      "[2, 691] loss: 0.717100203037262\n",
      "[2, 701] loss: 0.6944239139556885\n",
      "[2, 711] loss: 0.6720472574234009\n",
      "[2, 721] loss: 0.6132307052612305\n",
      "[2, 731] loss: 0.6245644688606262\n",
      "[2, 741] loss: 0.6365567445755005\n",
      "[2, 751] loss: 0.6838065385818481\n",
      "[2, 761] loss: 0.6493809223175049\n",
      "[2, 771] loss: 0.6386651992797852\n",
      "[2, 781] loss: 0.6601074934005737\n",
      "[2, 791] loss: 0.6818861961364746\n",
      "[2, 801] loss: 0.718411922454834\n",
      "[2, 811] loss: 0.6900412440299988\n",
      "[2, 821] loss: 0.6547104716300964\n",
      "[3, 1] loss: 0.6876075267791748\n",
      "[3, 11] loss: 0.6864302158355713\n",
      "[3, 21] loss: 0.6577733159065247\n",
      "[3, 31] loss: 0.6723988652229309\n",
      "[3, 41] loss: 0.6163697838783264\n",
      "[3, 51] loss: 0.6535524129867554\n",
      "[3, 61] loss: 0.6520965099334717\n",
      "[3, 71] loss: 0.6565483212471008\n",
      "[3, 81] loss: 0.6867578625679016\n",
      "[3, 91] loss: 0.6426464319229126\n",
      "[3, 101] loss: 0.6394140124320984\n",
      "[3, 111] loss: 0.6376259326934814\n",
      "[3, 121] loss: 0.6711786985397339\n",
      "[3, 131] loss: 0.6540907025337219\n",
      "[3, 141] loss: 0.7000877857208252\n",
      "[3, 151] loss: 0.6633909940719604\n",
      "[3, 161] loss: 0.6337423324584961\n",
      "[3, 171] loss: 0.6527089476585388\n",
      "[3, 181] loss: 0.6707000136375427\n",
      "[3, 191] loss: 0.6566780805587769\n",
      "[3, 201] loss: 0.6231507062911987\n",
      "[3, 211] loss: 0.6465293169021606\n",
      "[3, 221] loss: 0.6742556095123291\n",
      "[3, 231] loss: 0.6199190616607666\n",
      "[3, 241] loss: 0.6698095202445984\n",
      "[3, 251] loss: 0.6658461093902588\n",
      "[3, 261] loss: 0.7230960130691528\n",
      "[3, 271] loss: 0.6660575866699219\n",
      "[3, 281] loss: 0.6831541061401367\n",
      "[3, 291] loss: 0.6657335758209229\n",
      "[3, 301] loss: 0.627742350101471\n",
      "[3, 311] loss: 0.6777196526527405\n",
      "[3, 321] loss: 0.6359614729881287\n",
      "[3, 331] loss: 0.6529009938240051\n",
      "[3, 341] loss: 0.7055256962776184\n",
      "[3, 351] loss: 0.6528428792953491\n",
      "[3, 361] loss: 0.6710723042488098\n",
      "[3, 371] loss: 0.6896924376487732\n",
      "[3, 381] loss: 0.679015576839447\n",
      "[3, 391] loss: 0.5922589898109436\n",
      "[3, 401] loss: 0.7156655192375183\n",
      "[3, 411] loss: 0.6355816125869751\n",
      "[3, 421] loss: 0.6761834621429443\n",
      "[3, 431] loss: 0.6108613610267639\n",
      "[3, 441] loss: 0.7261002063751221\n",
      "[3, 451] loss: 0.6457091569900513\n",
      "[3, 461] loss: 0.6679947376251221\n",
      "[3, 471] loss: 0.6826630234718323\n",
      "[3, 481] loss: 0.6575791239738464\n",
      "[3, 491] loss: 0.696066677570343\n",
      "[3, 501] loss: 0.6599751710891724\n",
      "[3, 511] loss: 0.6633890271186829\n",
      "[3, 521] loss: 0.6451953053474426\n",
      "[3, 531] loss: 0.62724369764328\n",
      "[3, 541] loss: 0.6611601114273071\n",
      "[3, 551] loss: 0.6926213502883911\n",
      "[3, 561] loss: 0.6572607755661011\n",
      "[3, 571] loss: 0.697243332862854\n",
      "[3, 581] loss: 0.6830132603645325\n",
      "[3, 591] loss: 0.7151410579681396\n",
      "[3, 601] loss: 0.6541518568992615\n",
      "[3, 611] loss: 0.6777093410491943\n",
      "[3, 621] loss: 0.6256244778633118\n",
      "[3, 631] loss: 0.6450915932655334\n",
      "[3, 641] loss: 0.6656472086906433\n",
      "[3, 651] loss: 0.6722646355628967\n",
      "[3, 661] loss: 0.6377675533294678\n",
      "[3, 671] loss: 0.6867246627807617\n",
      "[3, 681] loss: 0.6875697374343872\n",
      "[3, 691] loss: 0.702171802520752\n",
      "[3, 701] loss: 0.602953314781189\n",
      "[3, 711] loss: 0.68449866771698\n",
      "[3, 721] loss: 0.651136577129364\n",
      "[3, 731] loss: 0.6374951601028442\n",
      "[3, 741] loss: 0.6655495762825012\n",
      "[3, 751] loss: 0.6660685539245605\n",
      "[3, 761] loss: 0.6583343148231506\n",
      "[3, 771] loss: 0.7349093556404114\n",
      "[3, 781] loss: 0.7571360468864441\n",
      "[3, 791] loss: 0.6436069011688232\n",
      "[3, 801] loss: 0.6137228012084961\n",
      "[3, 811] loss: 0.6571440100669861\n",
      "[3, 821] loss: 0.6394103765487671\n",
      "Finished Training\n",
      "Accuracy: 0.6154\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Loss       0.00      0.00      0.00      5060\n",
      "         Win       0.62      1.00      0.76      8096\n",
      "\n",
      "    accuracy                           0.62     13156\n",
      "   macro avg       0.31      0.50      0.38     13156\n",
      "weighted avg       0.38      0.62      0.47     13156\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carlo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\carlo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\carlo\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to nba_bert_model.pth\n",
      "\n",
      "Model Information:\n",
      "Model architecture: BertForSequenceClassification(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-11): 12 x BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSdpaSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pooler): BertPooler(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (activation): Tanh()\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
      ")\n",
      "Number of parameters: 109483778\n",
      "Trainable parameters: 109483778\n",
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AdamW\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# Cargar datos\n",
    "games = pd.read_csv('C:\\\\Users\\\\carlo\\\\Documents\\\\Proyectos\\\\NBA_predict\\\\csv\\\\game.csv')\n",
    "game_info = pd.read_csv('C:\\\\Users\\\\carlo\\\\Documents\\\\Proyectos\\\\NBA_predict\\\\csv\\\\game_info.csv')\n",
    "\n",
    "# Fusionar DataFrames\n",
    "games_full = games.merge(game_info, on='game_id', how='left', suffixes=('_x', '_y'))\n",
    "\n",
    "# Convertir 'game_date_x' a datetime y seleccionar columnas relevantes\n",
    "games_full['game_date'] = pd.to_datetime(games_full['game_date_x'])\n",
    "games_full.sort_values(by='game_date', inplace=True)\n",
    "features = games_full[['team_abbreviation_home', 'team_abbreviation_away']]\n",
    "target = (games_full['wl_home'] == 'W').astype(int)\n",
    "\n",
    "# Dividir los datos\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preparar secuencias para Transformer usando el tokenizador de BERT\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def encode_features(df):\n",
    "    input_texts = df['team_abbreviation_home'] + \" vs \" + df['team_abbreviation_away']\n",
    "    inputs = tokenizer(input_texts.tolist(), padding='max_length', max_length=20, truncation=True, return_tensors=\"pt\")\n",
    "    return inputs\n",
    "\n",
    "# Dataset personalizado para manejar los datos\n",
    "class GameDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.features.items()}\n",
    "        item['labels'] = torch.tensor(self.labels.iloc[idx], dtype=torch.long)\n",
    "        return item\n",
    "\n",
    "# Codificar las características\n",
    "train_features = encode_features(X_train)\n",
    "test_features = encode_features(X_test)\n",
    "\n",
    "train_dataset = GameDataset(train_features, y_train)\n",
    "test_dataset = GameDataset(test_features, y_test)\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Cargar el modelo de Transformers\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Optimizador\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "# Entrenamiento del modelo\n",
    "model.train()\n",
    "for epoch in range(3):  # Loop over the dataset multiple times\n",
    "    for i, batch in enumerate(train_loader, 0):\n",
    "        inputs = {'input_ids': batch['input_ids'].to(device), 'attention_mask': batch['attention_mask'].to(device), 'labels': batch['labels'].to(device)}\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(**inputs)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 10 == 0:  # Print every 10 mini-batches\n",
    "            print(f'[{epoch + 1}, {i + 1}] loss: {loss.item()}')\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "# Evaluar el modelo\n",
    "model.eval()  # Cambiar el modelo a modo de evaluación\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        inputs = {\n",
    "            'input_ids': batch['input_ids'].to(device),\n",
    "            'attention_mask': batch['attention_mask'].to(device),\n",
    "            'labels': batch['labels'].to(device)\n",
    "        }\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        preds = torch.argmax(logits, dim=-1).cpu().numpy()\n",
    "        labels = inputs['labels'].cpu().numpy()\n",
    "        all_preds.extend(preds)\n",
    "        all_labels.extend(labels)\n",
    "\n",
    "# Calcular la precisión\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "print(f'Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Reporte de clasificación\n",
    "print(classification_report(all_labels, all_preds, target_names=['Loss', 'Win']))\n",
    "\n",
    "# Guardar el modelo\n",
    "model_save_path = 'nba_bert_model.pth'\n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "print(f'Model saved to {model_save_path}')\n",
    "\n",
    "# Extraer y mostrar información del modelo\n",
    "print(\"\\nModel Information:\")\n",
    "print(f\"Model architecture: {model}\")\n",
    "print(f\"Number of parameters: {sum(p.numel() for p in model.parameters())}\")\n",
    "print(f\"Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad)}\")\n",
    "print(f\"Device: {device}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
